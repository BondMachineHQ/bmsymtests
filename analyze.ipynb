{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from IPython import display\n",
    "import sympy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "%run config.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colors for terminal output\n",
    "GREEN = \"\\033[92m\"\n",
    "RED = \"\\033[91m\"\n",
    "YELLOW = \"\\033[93m\"\n",
    "BLUE = \"\\033[94m\"\n",
    "CYAN = \"\\033[96m\"\n",
    "MAGENTA = \"\\033[95m\"\n",
    "BOLD = \"\\033[1m\"\n",
    "UNDERLINE = \"\\033[4m\"\n",
    "STANDARD = \"\\033[0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequencer and Desequencer\n",
    "def csv2sequence(csvFile,seqFile,pref):\n",
    "\twith open(csvFile, 'r') as f:\n",
    "\t\tlines = f.readlines()\n",
    "\t\twith open(seqFile, 'w') as g:\n",
    "\t\t\tfor line in lines:\n",
    "\t\t\t\tfor token in line.split(','):\n",
    "\t\t\t\t\tif token.startswith(pref):\n",
    "\t\t\t\t\t\ttoken = token[len(pref):]\n",
    "\t\t\t\t\ttoken = token.strip()\n",
    "\t\t\t\t\tif token!=\"\" and token!='\\n':\n",
    "\t\t\t\t\t\tg.write(token+'\\n')\n",
    "\n",
    "def sequence2csv(seqFile,csvFile,dataWidth,pref):\n",
    "\twith open(seqFile, 'r') as f:\n",
    "\t\tlines = f.readlines()\n",
    "\t\tdataW = dataWidth\n",
    "\t\twith open(csvFile, 'w') as g:\n",
    "\t\t\tfor line in lines:\n",
    "\t\t\t\tg.write(pref+line.strip())\n",
    "\t\t\t\tdataW -= 1\n",
    "\t\t\t\tif dataW==0:\n",
    "\t\t\t\t\tg.write('\\n')\n",
    "\t\t\t\t\tdataW = dataWidth\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tg.write(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to show the generated function\n",
    "def showFunction():\n",
    "\texec(open(\"generated.py\").read())\n",
    "\timport IPython.display as disp\n",
    "\tdisp.display(spExpr)\n",
    "# showFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to show the generated BM\n",
    "def showBM():\n",
    "\tdisplay.Image(\"bondmachine.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "environment creation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function create an environment with a random mathematical expression\n",
    "def generateRandom():\n",
    "\t! echo \"SOURCE_FLEXPY=generated.py\" > source.mk\n",
    "\t! make clean > /dev/null\n",
    "\t! echo \"SOURCE_FLEXPY=generated.py\" > source.mk\n",
    "\t! flexpytester --generate -e symbols -s generated.py -i inputs.csv -o outputs.csv --prefix --config decayFactor=3 > /dev/null\n",
    "\t! bmhelper apply > /dev/null \n",
    "\t! make show > /dev/null\n",
    "\tcsv2sequence('inputs.csv','inputs.seq',\"0f\")\n",
    "\tcsv2sequence('outputs.csv','outputs.seq',\"0f\")\n",
    "# generateRandom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate the test cases of an existing mathematical expression\n",
    "def generateExistent():\n",
    "\t! echo \"SOURCE_FLEXPY=generated.py\" > source.mk\n",
    "\t! make clean > /dev/null\n",
    "\t! echo \"SOURCE_FLEXPY=generated.py\" > source.mk\n",
    "\t! flexpytester --compute -e generated.py -i inputs.csv -o outputs.csv --prefix > /dev/null\n",
    "\t! bmhelper apply > /dev/null \n",
    "\t! make show > /dev/null\n",
    "\tcsv2sequence('inputs.csv','inputs.seq',\"0f\")\n",
    "\tcsv2sequence('outputs.csv','outputs.seq',\"0f\")\n",
    "# generateExistent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate the test cases of an existing single neuron within the library\n",
    "def generateNeuron(library, neuron):\n",
    "\t! echo \"SOURCE_BASM=out.basm\" > source.mk\n",
    "\t! make clean > /dev/null\n",
    "\t! echo \"SOURCE_BASM=out.basm\" > source.mk\n",
    "\t! rm -f notok\n",
    "\t! fragtester -neuron-lib-path {library} -fragment-file {neuron}.basm -save-expression generated.py || touch notok > /dev/null\n",
    "\tif os.path.exists(\"notok\"):\n",
    "\t\treturn False\n",
    "\t! flexpytester --compute -e generated.py -i inputs.csv -o outputs.csv --prefix > /dev/null\n",
    "\t! bmhelper apply > /dev/null\n",
    "\t! make show > /dev/null\n",
    "\tcsv2sequence('inputs.csv','inputs.seq',\"0f\")\n",
    "\tcsv2sequence('outputs.csv','outputs.seq',\"0f\")\n",
    "\t! echo \"{\" > statistics.json\n",
    "\t! echo -n \"\\\"\" >> statistics.json\n",
    "\t! echo -n {neuron} >> statistics.json\n",
    "\t! echo \"\\\": 1\" >> statistics.json\n",
    "\t! echo \"}\" >> statistics.json\n",
    "\treturn True\n",
    "# generateNeuron(\"library\", \"addargfullargfull\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate the test cases of an existing single neuron within the library\n",
    "def placeHolderNeuron(library, neuron):\n",
    "\t! echo \"{\" > statistics.json\n",
    "\t! echo -n \"\\\"\" >> statistics.json\n",
    "\t! echo -n {neuron} >> statistics.json\n",
    "\t! echo \"\\\": 0\" >> statistics.json\n",
    "\t! echo \"}\" >> statistics.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Simulation beckends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BondMachine internal simulator\n",
    "def runSimbatch():\n",
    "\t! make simbatch > /dev/null\n",
    "# runSimbatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BondMachine hardware run\n",
    "def runBMsim():\n",
    "\t! make deploycollect > /dev/null\n",
    "\t! mv working_dir/bmsim_outputs.seq bmsim_outputs.seq\n",
    "\t! bondmachine -bondmachine-file working_dir/bondmachine.json -list-outputs | wc -l > num_outputs.txt\n",
    "\t# Read the number of outputs\n",
    "\twith open('num_outputs.txt','r') as f:\n",
    "\t\tnum_outputs = int(f.read())\n",
    "\tsequence2csv('bmsim_outputs.seq','bmsim_outputs.csv',num_outputs,\"\")\n",
    "# runBMsim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HLS simulator\n",
    "def rubHLSsim():\n",
    "\tprint (\"hlsim\")\n",
    "# runHLSsim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzeSimbatch():\n",
    "\t# Load the target outputs from the output.csv file\n",
    "\ttargetData = np.loadtxt('outputs.csv', delimiter=',')\n",
    "\tsimbatchData = np.loadtxt('simbatch_outputs.csv', delimiter=',')\n",
    "\tsimbatchMSE=sklearn.metrics.mean_squared_error(targetData, simbatchData)\n",
    "\n",
    "\tdata = {\n",
    "\t\t\"Dataset\": [\"Sympy target\", \"Simbatch\"],\n",
    "\t\t\"MSE\" : [0.0, simbatchMSE]\n",
    "\t}\n",
    "\tdf = pd.DataFrame(data)\n",
    "\treturn df.style.hide(axis=\"index\"), simbatchMSE\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics management functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotHistogram(df):\n",
    "\t# Plot the histogram\n",
    "\tdf['occurrences'].plot(kind='bar', figsize=(10, 6), color='skyblue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadRun(mse):\n",
    "\twith open('statistics.json', 'r') as f:\n",
    "\t\tdata = json.load(f)\n",
    "\t\n",
    "\tdf = pd.DataFrame.from_dict(data, orient='index', columns=['occurrences'])\n",
    "\ttotOccurrences = df['occurrences'].sum()\n",
    "\tnewCol=mse\n",
    "\tif totOccurrences > 0:\n",
    "\t\tnewCol = newCol/totOccurrences\n",
    "\t\tdf['error'] = newCol\n",
    "\telse:\n",
    "\t\tdf['error'] = 0.0\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PatchGlobalStats(global_stats, df):\n",
    "\t# If the global statistics DataFrame is empty, initialize it with the same rows as the current DataFrame\n",
    "\tfor index, row in df.iterrows():\n",
    "\t\tif index not in global_stats.index:\n",
    "\t\t\tglobal_stats.loc[index] = [0.0, 0.0]\n",
    "\n",
    "\t# Sum the occurrences to the global statistics\n",
    "\tfor index, row in df.iterrows():\n",
    "\t\tglobal_stats.at[index, 'occurrences'] += row['occurrences']\n",
    "\t\tglobal_stats.at[index, 'error'] += row['error']\n",
    "\t# Save the updated global statistics\n",
    "\tglobal_stats.to_csv('global_statistics')\n",
    "\treturn global_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGlobalStats():\n",
    "\t# Load the global statistics from the CSV file if it exists\n",
    "\tif os.path.exists('global_statistics'):\n",
    "\t\tglobal_stats = pd.read_csv('global_statistics', index_col=0)\n",
    "\telse:\n",
    "\t\t# Create an empty DataFrame with the same columns as the global statistics\n",
    "\t\tglobal_stats = pd.DataFrame(columns=['occurrences', 'error'])\n",
    "\treturn global_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interactive sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single run test, it executes the entire process and return a DataFrame (df) with the errors\n",
    "if False:\t\n",
    "\t# generateRandom()\n",
    "\t# generateExistent()\n",
    "\tgenerateNeuron(\"library\", \"addargfullargfull\")\n",
    "\trunSimbatch()\n",
    "\t# runBMsim()\n",
    "\t# runHLSsim()\n",
    "\terrors,mse=analyzeSimbatch()\n",
    "\t# errors\n",
    "\tdf=loadRun(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the historical global statistics and patch it with the new data (df)\n",
    "if False:\n",
    "\tgs=loadGlobalStats()\n",
    "\tgs=PatchGlobalStats(gs, df)\n",
    "\tgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>occurrences</th>\n",
       "      <th>error</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>powargimagargimag</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multargimagargfull</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>multargimagnumimag</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>powargimagnumfull</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    occurrences  error\n",
       "powargimagargimag           0.0    0.0\n",
       "multargimagargfull          0.0    0.0\n",
       "multargimagnumimag          0.0    0.0\n",
       "powargimagnumfull           0.0    0.0"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Iterate al the neurons in the library and test them singly, patching the global statistics\n",
    "for neuronFile in os.listdir(\"library\"):\n",
    "\tif not neuronFile.endswith(\".basm\"):\n",
    "\t\tcontinue\n",
    "\tneuron = neuronFile.split(\".\")[0]\n",
    "\t# generateRandom()\n",
    "\t# generateExistent()\n",
    "\tif generateNeuron(\"library\", neuron):\n",
    "\t\trunSimbatch()\n",
    "\t\t# runBMsim()\n",
    "\t\t# runHLSsim()\n",
    "\t\terrors,mse=analyzeSimbatch()\n",
    "\telse:\n",
    "\t\tplaceHolderNeuron(\"library\", neuron)\n",
    "\n",
    "\tdf=loadRun(0.0)\n",
    "\tgs=loadGlobalStats()\n",
    "\tgs=PatchGlobalStats(gs, df)\n",
    "gs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
