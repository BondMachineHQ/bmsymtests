{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import json\n",
    "import os\n",
    "import random\n",
    "from IPython import display\n",
    "import sympy as sp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sklearn\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "\n",
    "%run config.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colors for terminal output\n",
    "GREEN = \"\\033[92m\"\n",
    "RED = \"\\033[91m\"\n",
    "YELLOW = \"\\033[93m\"\n",
    "BLUE = \"\\033[94m\"\n",
    "CYAN = \"\\033[96m\"\n",
    "MAGENTA = \"\\033[95m\"\n",
    "BOLD = \"\\033[1m\"\n",
    "UNDERLINE = \"\\033[4m\"\n",
    "STANDARD = \"\\033[0m\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequencer and Desequencer\n",
    "def csv2sequence(csvFile,seqFile,pref):\n",
    "\twith open(csvFile, 'r') as f:\n",
    "\t\tlines = f.readlines()\n",
    "\t\twith open(seqFile, 'w') as g:\n",
    "\t\t\tfor line in lines:\n",
    "\t\t\t\tfor token in line.split(','):\n",
    "\t\t\t\t\tif token.startswith(pref):\n",
    "\t\t\t\t\t\ttoken = token[len(pref):]\n",
    "\t\t\t\t\ttoken = token.strip()\n",
    "\t\t\t\t\tif token!=\"\" and token!='\\n':\n",
    "\t\t\t\t\t\tg.write(token+'\\n')\n",
    "\n",
    "def sequence2csv(seqFile,csvFile,dataWidth,pref):\n",
    "\twith open(seqFile, 'r') as f:\n",
    "\t\tlines = f.readlines()\n",
    "\t\tdataW = dataWidth\n",
    "\t\twith open(csvFile, 'w') as g:\n",
    "\t\t\tfor line in lines:\n",
    "\t\t\t\tg.write(pref+line.strip())\n",
    "\t\t\t\tdataW -= 1\n",
    "\t\t\t\tif dataW==0:\n",
    "\t\t\t\t\tg.write('\\n')\n",
    "\t\t\t\t\tdataW = dataWidth\n",
    "\t\t\t\telse:\n",
    "\t\t\t\t\tg.write(',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to show the generated function\n",
    "def showFunction():\n",
    "\texec(open(\"generated.py\").read())\n",
    "\timport IPython.display as disp\n",
    "\tdisp.display(spExpr)\n",
    "# showFunction()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to show the generated BM\n",
    "def showBM():\n",
    "\tdisplay.Image(\"bondmachine.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def highlightDone(val):\n",
    "    color = 'green' if val > 0.0 else 'red'\n",
    "    return f'background-color: {color}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "environment creation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function create an environment with a random mathematical expression\n",
    "def generateRandom():\n",
    "\t! echo \"SOURCE_FLEXPY=generated.py\" > source.mk\n",
    "\t! make clean > /dev/null\n",
    "\t! echo \"SOURCE_FLEXPY=generated.py\" > source.mk\n",
    "\t! flexpytester --generate -e symbols -s generated.py -i inputs.csv -o outputs.csv --prefix --config decayFactor=3 > /dev/null\n",
    "\t! bmhelper apply > /dev/null \n",
    "\t! make show > /dev/null\n",
    "\tcsv2sequence('inputs.csv','inputs.seq',\"0f\")\n",
    "\tcsv2sequence('outputs.csv','outputs.seq',\"0f\")\n",
    "# generateRandom()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate the test cases of an existing mathematical expression\n",
    "def generateExistent(functionFile):\n",
    "\t! echo \"SOURCE_FLEXPY=generated.py\" > source.mk\n",
    "\t! make clean > /dev/null\n",
    "\t! echo \"SOURCE_FLEXPY=generated.py\" > source.mk\n",
    "\t! flexpytester --compute -e generated.py -i inputs.csv -o outputs.csv --prefix > /dev/null 2>&1\n",
    "\t! bmhelper apply > /dev/null 2>&1\n",
    "\t! make show > /dev/null 2>&1\n",
    "\tcsv2sequence('inputs.csv','inputs.seq',\"0f\")\n",
    "\tcsv2sequence('outputs.csv','outputs.seq',\"0f\")\n",
    "# generateExistent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate the test cases of an existing single neuron within the library\n",
    "def generateNeuron(library, neuron, seq, benchcore):\n",
    "\t! echo \"SOURCE_BASM=out.basm\" > source.mk\n",
    "\t! make clean > /dev/null\n",
    "\t! echo \"SOURCE_BASM=out.basm\" > source.mk\n",
    "\t! rm -f notok\n",
    "\tif benchcore:\n",
    "\t\t! echo \"BENCHCOREV2_FILE=sicv2\" >> source.mk\n",
    "\t\t! echo \"SIMBATCH_ARGS=-b\" >> source.mk\n",
    "\t\t! fragtester -neuron-lib-path {library} -fragment-file {neuron}.basm -save-expression generated.py -seq {seq} -create-bmapi bmapi.json -build-app -app-flavor cpynqapibenchv2 -app-file expression.c -sicv2-endpoints sicv2 || touch notok > /dev/null\n",
    "\telse:\n",
    "\t\t! fragtester -neuron-lib-path {library} -fragment-file {neuron}.basm -save-expression generated.py -seq {seq} -create-bmapi bmapi.json -build-app -app-flavor cpynqapi -app-file expression.c || touch notok > /dev/null\n",
    "\tif os.path.exists(\"notok\"):\n",
    "\t\treturn False\n",
    "\t! flexpytester --compute -e generated.py -i inputs.csv -o outputs.csv --prefix > /dev/null 2>&1\n",
    "\t! bmhelper apply > /dev/null 2>&1\n",
    "\t! make hdl > /dev/null 2>&1\n",
    "\t! make show > /dev/null 2>&1\n",
    "\tcsv2sequence('inputs.csv','inputs.seq',\"0f\")\n",
    "\tcsv2sequence('outputs.csv','outputs.seq',\"0f\")\n",
    "\treturn True\n",
    "# generateNeuron(\"library\", \"cosargreal\", \"0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate the test cases of an existing single neuron within the library\n",
    "def getNeuronSeq(library, neuron):\n",
    "\t! rm -f notok\n",
    "\t! fragtester -neuron-lib-path {library} -fragment-file {neuron}.basm -save-expression generated.py  || touch notok > /dev/null\n",
    "\tif os.path.exists(\"notok\"):\n",
    "\t\treturn \"0\"\n",
    "\t! fragtester -neuron-lib-path {library} -fragment-file {neuron}.basm -save-expression generated.py -describe | grep \"Sequences\" | cut -d' ' -f2 > seqs.txt\n",
    "\tseq=1\n",
    "\twith open(\"seqs.txt\", \"r\") as f:\n",
    "\t\tlines = f.readlines()\n",
    "\t\tfor line in lines:\n",
    "\t\t\tseq=line.strip()\n",
    "\t\t\treturn seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to generate the test cases of an existing single neuron within the library\n",
    "def placeHolderNeuron(library, neuron):\n",
    "\t! echo \"{\" > statistics.json\n",
    "\t! echo -n \"\\\"\" >> statistics.json\n",
    "\t! echo -n {neuron} >> statistics.json\n",
    "\t! echo \"\\\": 0\" >> statistics.json\n",
    "\t! echo \"}\" >> statistics.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Simulation beckends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BondMachine internal simulator\n",
    "def runSimbatch():\n",
    "\t! make simbatch > /dev/null\n",
    "# runSimbatch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# BondMachine hardware run\n",
    "def runBMsim():\n",
    "\t! make deploycollect > /dev/null\n",
    "\t! mv working_dir/bmsim_outputs.seq bmsim_outputs.seq\n",
    "\t! bondmachine -bondmachine-file working_dir/bondmachine.json -list-outputs | wc -l > num_outputs.txt\n",
    "\t# Read the number of outputs\n",
    "\twith open('num_outputs.txt','r') as f:\n",
    "\t\tnum_outputs = int(f.read())\n",
    "\tsequence2csv('bmsim_outputs.seq','bmsim_outputs.csv',num_outputs,\"\")\n",
    "# runBMsim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HLS simulator\n",
    "def runHLSsim():\n",
    "\tprint (\"hlsim\")\n",
    "# runHLSsim()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzeSimbatch():\n",
    "\t# Load the target outputs from the output.csv file\n",
    "\ttargetData = np.loadtxt('outputs.csv', delimiter=',')\n",
    "\tsimbatchData = np.loadtxt('simbatch_outputs.csv', delimiter=',')\n",
    "\tlatency = False\n",
    "\n",
    "\tif benchcore:\n",
    "\t\tbenchcoreData = simbatchData[:, -1]\n",
    "\t\t# Move the last column,if there is a benchcore\n",
    "\t\tsimbatchData = np.delete(simbatchData, -1, axis=1)\n",
    "\n",
    "\tsimbatchMSE=sklearn.metrics.mean_squared_error(targetData, simbatchData)\n",
    "\n",
    "\tif benchcore:\n",
    "\t\tlatency = benchcoreData.mean()\n",
    "\t\tdata = {\n",
    "\t\t\t\"Dataset\": [\"Sympy target\", \"Simbatch\",\"Latency\"],\n",
    "\t\t\t\"MSE\" : [0.0, simbatchMSE, latency]\n",
    "\t\t}\n",
    "\telse:\n",
    "\t\tdata = {\n",
    "\t\t\t\"Dataset\": [\"Sympy target\", \"Simbatch\"],\n",
    "\t\t\t\"MSE\" : [0.0, simbatchMSE]\n",
    "\t\t}\n",
    "\tdf = pd.DataFrame(data)\n",
    "\treturn df.style.hide(axis=\"index\"), simbatchMSE, latency\n",
    "\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyzeBMsim():\n",
    "\t# Load the target outputs from the output.csv file\n",
    "\ttargetData = np.loadtxt('outputs.csv', delimiter=',')\n",
    "\tbmsimData = np.loadtxt('bmsim_outputs.csv', delimiter=',')\n",
    "\tlatency = False\n",
    "\n",
    "\tif benchcore:\n",
    "\t\tbenchcoreData = bmsimData[:, -1]\n",
    "\t\t# Move the last column,if there is a benchcore\n",
    "\t\tbmsimData = np.delete(bmsimData, -1, axis=1)\n",
    "\n",
    "\tbmsimMSE=sklearn.metrics.mean_squared_error(targetData, bmsimData)\n",
    "\n",
    "\tif benchcore:\n",
    "\t\tlatency = benchcoreData.mean()\n",
    "\t\tdata = {\n",
    "\t\t\t\"Dataset\": [\"Sympy target\", \"BMsim\",\"Latency\"],\n",
    "\t\t\t\"MSE\" : [0.0, bmsimMSE, latency]\n",
    "\t\t}\n",
    "\telse:\n",
    "\t\tdata = {\n",
    "\t\t\t\"Dataset\": [\"Sympy target\", \"BMsim\"],\n",
    "\t\t\t\"MSE\" : [0.0, bmsimMSE]\n",
    "\t\t}\n",
    "\tdf = pd.DataFrame(data)\n",
    "\treturn df.style.hide(axis=\"index\"), bmsimMSE, latency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics management functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plotHistogram(df):\n",
    "\t# Plot the histogram\n",
    "\tdf['bsimoccurrences'].plot(kind='bar', figsize=(10, 6), color='skyblue')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadBsimRun(mse,latency):\n",
    "\twith open('statistics.json', 'r') as f:\n",
    "\t\tdata = json.load(f)\n",
    "\t\n",
    "\tdf = pd.DataFrame.from_dict(data, orient='index', columns=['bsimoccurrences'])\n",
    "\ttotOccurrences = df['bsimoccurrences'].sum()\n",
    "\tnewCol=mse\n",
    "\tif totOccurrences > 0:\n",
    "\t\tnewCol = newCol/totOccurrences\n",
    "\t\tdf['bsimerror'] = newCol\n",
    "\telse:\n",
    "\t\tdf['bsimerror'] = 0.0\n",
    "\tif latency:\n",
    "\t\tdf['bsimlatency'] = latency\n",
    "\t\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadBMsimRun(mse,latency):\n",
    "\twith open('statistics.json', 'r') as f:\n",
    "\t\tdata = json.load(f)\n",
    "\t\n",
    "\tdf = pd.DataFrame.from_dict(data, orient='index', columns=['bmoccurrences'])\n",
    "\ttotOccurrences = df['bmoccurrences'].sum()\n",
    "\tnewCol=mse\n",
    "\tif totOccurrences > 0:\n",
    "\t\tnewCol = newCol/totOccurrences\n",
    "\t\tdf['bmerror'] = newCol\n",
    "\telse:\n",
    "\t\tdf['bmerror'] = 0.0\n",
    "\tif latency:\n",
    "\t\tdf['bmlatency'] = latency\n",
    "\treturn df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PatchBsimGlobalStats(global_stats, df):\n",
    "\t# If the global statistics DataFrame is empty, initialize it with the same rows as the current DataFrame\n",
    "\tfor index, row in df.iterrows():\n",
    "\t\tif index not in global_stats.index:\n",
    "\t\t\tglobal_stats.loc[index] = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "\n",
    "\t# Sum the occurrences to the global statistics\n",
    "\tfor index, row in df.iterrows():\n",
    "\t\tif row['bsimoccurrences'] > 0:\n",
    "\t\t\tfirstRun=False\n",
    "\t\t\tif global_stats.at[index, 'bsimoccurrences'] == 0:\n",
    "\t\t\t\tfirstRun=True\n",
    "\t\t\tsumErrors=global_stats.at[index, 'bsimoccurrences'] * global_stats.at[index, 'bsimerror'] + row['bsimerror']\n",
    "\t\t\tif 'bsimlatency' in row and (global_stats.at[index, 'bsimlatency']>0.0 or firstRun):\n",
    "\t\t\t\tsumLatencies=global_stats.at[index, 'bsimoccurrences'] * global_stats.at[index, 'bsimlatency'] + row['bsimlatency']\n",
    "\t\t\tglobal_stats.at[index, 'bsimoccurrences'] += row['bsimoccurrences']\n",
    "\t\t\tglobal_stats.at[index, 'bsimerror'] = sumErrors / global_stats.at[index, 'bsimoccurrences']\n",
    "\t\t\tif 'bsimlatency' in row and (global_stats.at[index, 'bsimlatency']>0.0 or firstRun):\n",
    "\t\t\t\tglobal_stats.at[index, 'bsimlatency'] = sumLatencies / global_stats.at[index, 'bsimoccurrences']\n",
    "\n",
    "\t# Save the updated global statistics\n",
    "\tglobal_stats.to_csv('global_statistics')\n",
    "\treturn global_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PatchBMsimGlobalStats(global_stats, df):\n",
    "\t# If the global statistics DataFrame is empty, initialize it with the same rows as the current DataFrame\n",
    "\tfor index, row in df.iterrows():\n",
    "\t\tif index not in global_stats.index:\n",
    "\t\t\tglobal_stats.loc[index] = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
    "\n",
    "\t# Sum the occurrences to the global statistics\n",
    "\tfor index, row in df.iterrows():\n",
    "\t\tif row['bmoccurrences'] > 0:\n",
    "\t\t\tfirstRun=False\n",
    "\t\t\tif global_stats.at[index, 'bmoccurrences'] == 0:\n",
    "\t\t\t\tfirstRun=True\n",
    "\t\t\tsumErrors=global_stats.at[index, 'bmoccurrences'] * global_stats.at[index, 'bmerror'] + row['bmerror']\n",
    "\t\t\tif 'bmlatency' in row and (global_stats.at[index, 'bmlatency']>0.0 or firstRun):\n",
    "\t\t\t\tsumLatencies=global_stats.at[index, 'bmoccurrences'] * global_stats.at[index, 'bmlatency'] + row['bmlatency']\n",
    "\t\t\tglobal_stats.at[index, 'bmoccurrences'] += row['bmoccurrences']\n",
    "\t\t\tglobal_stats.at[index, 'bmerror'] = sumErrors / global_stats.at[index, 'bmoccurrences']\n",
    "\t\t\tif 'bmlatency' in row and (global_stats.at[index, 'bmlatency']>0.0 or firstRun):\n",
    "\t\t\t\tglobal_stats.at[index, 'bmlatency'] = sumLatencies / global_stats.at[index, 'bmoccurrences']\n",
    "\n",
    "\t# Save the updated global statistics\n",
    "\tglobal_stats.to_csv('global_statistics')\n",
    "\treturn global_stats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadGlobalStats():\n",
    "\t# Load the global statistics from the CSV file if it exists\n",
    "\tif os.path.exists('global_statistics'):\n",
    "\t\tglobal_stats = pd.read_csv('global_statistics', index_col=0)\n",
    "\t\tglobal_stats.sort_index(inplace=True)\n",
    "\telse:\n",
    "\t\t# Create an empty DataFrame with the same columns as the global statistics\n",
    "\t\tglobal_stats = pd.DataFrame(columns=['bsimoccurrences', 'bsimerror', 'bmoccurrences', 'bmerror','bmlatency', 'bsimlatency'])\n",
    "\treturn global_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def latencyHistogram(dataFile, latencyCol, title):\n",
    "\tdf = pd.read_csv(dataFile)\n",
    "\tdf.columns = ['error', latencyCol]\n",
    "\timport matplotlib.pyplot as plt\n",
    "\n",
    "\tplt.figure(figsize=(10, 6))\n",
    "\tplt.hist(df[latencyCol], bins=30, color='skyblue', edgecolor='black')\n",
    "\tplt.title(title)\n",
    "\tplt.xlabel('Latency')\n",
    "\tplt.ylabel('Frequency')\n",
    "\tplt.grid(True)\n",
    "\tplt.show()\n",
    "\treturn plt.gcf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compareLatencyDistributions(bsimData, bmsimData):\n",
    "\t\"\"\"\n",
    "\tCompare two latency distributions using statistical tests and visualizations.\n",
    "\t\n",
    "\tArgs:\n",
    "\t\tbsimData: pandas Series of Simbatch latencies\n",
    "\t\tbmsimData: pandas Series of BMsim latencies\n",
    "\t\n",
    "\tReturns:\n",
    "\t\tDictionary with comparison results\n",
    "\t\"\"\"\n",
    "\tfrom scipy import stats\n",
    "\timport matplotlib.pyplot as plt\n",
    "\t\n",
    "\tresults = {}\n",
    "\t\n",
    "\t# 1. Descriptive Statistics\n",
    "\tresults['bsim_stats'] = {\n",
    "\t\t'mean': bsimData.mean(),\n",
    "\t\t'median': bsimData.median(),\n",
    "\t\t'std': bsimData.std(),\n",
    "\t\t'min': bsimData.min(),\n",
    "\t\t'max': bsimData.max(),\n",
    "\t\t'q25': bsimData.quantile(0.25),\n",
    "\t\t'q75': bsimData.quantile(0.75)\n",
    "\t}\n",
    "\t\n",
    "\tresults['bmsim_stats'] = {\n",
    "\t\t'mean': bmsimData.mean(),\n",
    "\t\t'median': bmsimData.median(),\n",
    "\t\t'std': bmsimData.std(),\n",
    "\t\t'min': bmsimData.min(),\n",
    "\t\t'max': bmsimData.max(),\n",
    "\t\t'q25': bmsimData.quantile(0.25),\n",
    "\t\t'q75': bmsimData.quantile(0.75)\n",
    "\t}\n",
    "\t\n",
    "\t# 2. Statistical Tests\n",
    "\t# Kolmogorov-Smirnov Test (are distributions different?)\n",
    "\tks_stat, ks_pvalue = stats.ks_2samp(bsimData, bmsimData)\n",
    "\tresults['ks_test'] = {\n",
    "\t\t'statistic': ks_stat,\n",
    "\t\t'p_value': ks_pvalue,\n",
    "\t\t'significant': ks_pvalue < 0.05\n",
    "\t}\n",
    "\t\n",
    "\t# Mann-Whitney U Test (non-parametric comparison of medians)\n",
    "\tmw_stat, mw_pvalue = stats.mannwhitneyu(bsimData, bmsimData, alternative='two-sided')\n",
    "\tresults['mann_whitney'] = {\n",
    "\t\t'statistic': mw_stat,\n",
    "\t\t'p_value': mw_pvalue,\n",
    "\t\t'significant': mw_pvalue < 0.05\n",
    "\t}\n",
    "\t\n",
    "\t# Wasserstein Distance (Earth Mover's Distance)\n",
    "\twasserstein = stats.wasserstein_distance(bsimData, bmsimData)\n",
    "\tresults['wasserstein_distance'] = wasserstein\n",
    "\t\n",
    "\t# 3. Visualizations\n",
    "\tfig, axes = plt.subplots(2, 2, figsize=(14, 10))\n",
    "\t\n",
    "\t# Overlaid histograms\n",
    "\taxes[0, 0].hist(bsimData, bins=30, alpha=0.5, label='Simbatch', color='blue', edgecolor='black')\n",
    "\taxes[0, 0].hist(bmsimData, bins=30, alpha=0.5, label='BMsim', color='red', edgecolor='black')\n",
    "\taxes[0, 0].set_xlabel('Latency')\n",
    "\taxes[0, 0].set_ylabel('Frequency')\n",
    "\taxes[0, 0].set_title('Overlaid Histograms')\n",
    "\taxes[0, 0].legend()\n",
    "\taxes[0, 0].grid(True, alpha=0.3)\n",
    "\t\n",
    "\t# Box plots\n",
    "\taxes[0, 1].boxplot([bsimData, bmsimData], labels=['Simbatch', 'BMsim'])\n",
    "\taxes[0, 1].set_ylabel('Latency')\n",
    "\taxes[0, 1].set_title('Box Plot Comparison')\n",
    "\taxes[0, 1].grid(True, alpha=0.3)\n",
    "\t\n",
    "\t# Cumulative Distribution Functions\n",
    "\taxes[1, 0].hist(bsimData, bins=50, cumulative=True, alpha=0.5, label='Simbatch', \n",
    "\t                color='blue', edgecolor='black', density=True)\n",
    "\taxes[1, 0].hist(bmsimData, bins=50, cumulative=True, alpha=0.5, label='BMsim', \n",
    "\t                color='red', edgecolor='black', density=True)\n",
    "\taxes[1, 0].set_xlabel('Latency')\n",
    "\taxes[1, 0].set_ylabel('Cumulative Probability')\n",
    "\taxes[1, 0].set_title('Cumulative Distribution Functions')\n",
    "\taxes[1, 0].legend()\n",
    "\taxes[1, 0].grid(True, alpha=0.3)\n",
    "\t\n",
    "\t# Q-Q Plot\n",
    "\tquantiles = np.linspace(0, 1, min(len(bsimData), len(bmsimData)))\n",
    "\tbsim_quantiles = bsimData.quantile(quantiles)\n",
    "\tbmsim_quantiles = bmsimData.quantile(quantiles)\n",
    "\taxes[1, 1].scatter(bsim_quantiles, bmsim_quantiles, alpha=0.5)\n",
    "\tmin_val = min(bsim_quantiles.min(), bmsim_quantiles.min())\n",
    "\tmax_val = max(bsim_quantiles.max(), bmsim_quantiles.max())\n",
    "\taxes[1, 1].plot([min_val, max_val], [min_val, max_val], 'r--', label='Perfect match')\n",
    "\taxes[1, 1].set_xlabel('Simbatch Quantiles')\n",
    "\taxes[1, 1].set_ylabel('BMsim Quantiles')\n",
    "\taxes[1, 1].set_title('Q-Q Plot')\n",
    "\taxes[1, 1].legend()\n",
    "\taxes[1, 1].grid(True, alpha=0.3)\n",
    "\t\n",
    "\tplt.tight_layout()\n",
    "\tplt.show()\n",
    "\t\n",
    "\t# Print summary\n",
    "\tprint(\"=\"*60)\n",
    "\tprint(\"LATENCY DISTRIBUTION COMPARISON\")\n",
    "\tprint(\"=\"*60)\n",
    "\tprint(f\"\\nSimbatch Statistics:\")\n",
    "\tprint(f\"  Mean: {results['bsim_stats']['mean']:.4f}\")\n",
    "\tprint(f\"  Median: {results['bsim_stats']['median']:.4f}\")\n",
    "\tprint(f\"  Std Dev: {results['bsim_stats']['std']:.4f}\")\n",
    "\tprint(f\"  Range: [{results['bsim_stats']['min']:.4f}, {results['bsim_stats']['max']:.4f}]\")\n",
    "\t\n",
    "\tprint(f\"\\nBMsim Statistics:\")\n",
    "\tprint(f\"  Mean: {results['bmsim_stats']['mean']:.4f}\")\n",
    "\tprint(f\"  Median: {results['bmsim_stats']['median']:.4f}\")\n",
    "\tprint(f\"  Std Dev: {results['bmsim_stats']['std']:.4f}\")\n",
    "\tprint(f\"  Range: [{results['bmsim_stats']['min']:.4f}, {results['bmsim_stats']['max']:.4f}]\")\n",
    "\t\n",
    "\tprint(f\"\\nStatistical Tests:\")\n",
    "\tprint(f\"  Kolmogorov-Smirnov Test:\")\n",
    "\tprint(f\"    Statistic: {results['ks_test']['statistic']:.4f}\")\n",
    "\tprint(f\"    P-value: {results['ks_test']['p_value']:.4e}\")\n",
    "\tprint(f\"    Distributions are {'DIFFERENT' if results['ks_test']['significant'] else 'SIMILAR'} (α=0.05)\")\n",
    "\t\n",
    "\tprint(f\"\\n  Mann-Whitney U Test:\")\n",
    "\tprint(f\"    Statistic: {results['mann_whitney']['statistic']:.4f}\")\n",
    "\tprint(f\"    P-value: {results['mann_whitney']['p_value']:.4e}\")\n",
    "\tprint(f\"    Medians are {'DIFFERENT' if results['mann_whitney']['significant'] else 'SIMILAR'} (α=0.05)\")\n",
    "\t\n",
    "\tprint(f\"\\n  Wasserstein Distance: {results['wasserstein_distance']:.4f}\")\n",
    "\tprint(f\"    (Lower is better, 0 = identical distributions)\")\n",
    "\tprint(\"=\"*60)\n",
    "\t\n",
    "\treturn results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interactive sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From here, it is possible to override the config.py settings and run specific parts, by defining all the variables are set to False\n",
    "\n",
    "# debug=True\n",
    "singleRun=True\n",
    "runMode=\"fragtester\"\n",
    "# singleRunPatch=True\n",
    "# fullRun=True\n",
    "runSimbatchTests=True\n",
    "runBmsimTests=True\n",
    "\n",
    "benchcore=True\n",
    "\n",
    "showLatencyDistribution=True\n",
    "\n",
    "neuronUnderTest = \"addargrealnumreal\"\n",
    "neuronSeq = \"0\"\n",
    "functionFile = \"generated.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Single run test, it executes the entire process and return a DataFrame (df) with the errors\n",
    "if singleRun:\n",
    "\tif runMode == \"random\":\n",
    "\t\tgenerateRandom()\n",
    "\telif runMode == \"existent\":\n",
    "\t\tgenerateExistent(functionFile)\n",
    "\telif runMode == \"fragtester\":\n",
    "\t\tgenerateNeuron(\"library\", neuronUnderTest, neuronSeq, benchcore)\n",
    "\telse:\n",
    "\t\tprint (RED + \"Unknown run mode: \" + runMode + STANDARD)\n",
    "\t\texit(1)\n",
    "\n",
    "\tif runSimbatchTests:\n",
    "\t\trunSimbatch()\n",
    "\t\terrors,mse,latency=analyzeSimbatch()\n",
    "\t\tdfbsim=loadBsimRun(mse,latency)\n",
    "\n",
    "\tif runBmsimTests:\n",
    "\t\trunBMsim()\n",
    "\t\terrors,mse,latency=analyzeBMsim()\n",
    "\t\tdfbm=loadBMsimRun(mse,latency)\n",
    "\t\n",
    "\t# runHLSsim()\n",
    "\n",
    "\tif showLatencyDistribution and runSimbatchTests:\n",
    "\t\tlbsimhist=latencyHistogram('simbatch_outputs.csv','bsimlatency','Simbatch Latency Distribution')\n",
    "\n",
    "\tif showLatencyDistribution and runBmsimTests:\n",
    "\t\tlbmsimhist=latencyHistogram('bmsim_outputs.csv','bmlatency','BM Latency Distribution')\n",
    "\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbsim if (singleRun and runSimbatchTests) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfbm if (singleRun and runBmsimTests) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbsimhist if (singleRun and runSimbatchTests) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lbmsimhist if (singleRun and runBmsimTests) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract latency columns for distribution comparison\n",
    "if singleRun and runSimbatchTests and runBmsimTests and showLatencyDistribution:\n",
    "\tbsimDataDF=pd.read_csv('simbatch_outputs.csv')\n",
    "\tbmsimDataDF=pd.read_csv('bmsim_outputs.csv')\n",
    "\t# Extract just the latency column (second column)\n",
    "\tbsimData = bsimDataDF.iloc[:, 1]\n",
    "\tbmsimData = bmsimDataDF.iloc[:, 1]\n",
    "\tcomparison_results = compareLatencyDistributions(bsimData, bmsimData)\n",
    "\t\n",
    "comparison_results if (singleRun and runSimbatchTests and runBmsimTests and showLatencyDistribution) else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display.Image(\"bondmachine.png\") if singleRun else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the historical global statistics and patch it with the new data (df) with the simbatch results\n",
    "if singleRunPatch and runSimbatchTests:\n",
    "\tgs=loadGlobalStats()\n",
    "\tgs=PatchBsimGlobalStats(gs, dfbsim)\n",
    "\tgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the historical global statistics and patch it with the new data (df) with the bmsim results\n",
    "if singleRunPatch and runBmsimTests:\n",
    "\tgs=loadGlobalStats()\n",
    "\tgs=PatchBMsimGlobalStats(gs, dfbm)\n",
    "\tgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs if singleRunPatch else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fullRun:\n",
    "\t# Iterate al the neurons in the library and test them singly, patching the global statistics\n",
    "\tgs=loadGlobalStats()\n",
    "\n",
    "\tfor neuronFile in os.listdir(\"library\"):\n",
    "\t\tif not neuronFile.endswith(\".basm\"):\n",
    "\t\t\tcontinue\n",
    "\t\tneuron = neuronFile.split(\".\")[0]\n",
    "\t\t# generateRandom()\n",
    "\t\t# generateExistent()\n",
    "\n",
    "\t\tif debug:\n",
    "\t\t\tprint(\"Evaluating neuron: \"+neuron)\n",
    "\n",
    "\t\t# Simbatch tests\n",
    "\t\tif runSimbatchTests and not(any(gs.index.str.startswith(neuron)) and gs.loc[gs.index.str.startswith(neuron), 'bsimoccurrences'].max() > 0):\n",
    "\t\t\tseq=getNeuronSeq(\"library\", neuron)\n",
    "\t\t\tif seq!=\"0\":\n",
    "\t\t\t\tfor i in range(0, int(seq)):\n",
    "\t\t\t\t\tif generateNeuron(\"library\", neuron, str(i), benchcore):\n",
    "\t\t\t\t\t\trunSimbatch()\n",
    "\t\t\t\t\t\terrors,mse,latency=analyzeSimbatch()\n",
    "\t\t\t\t\t\tdf=loadBsimRun(mse,latency)\n",
    "\t\t\t\t\t\tgs=PatchBsimGlobalStats(gs, df)\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tprint(f\"{RED}Error generating neuron {neuron} with sequence {seq}{STANDARD}\")\n",
    "\t\t\telse:\n",
    "\t\t\t\tplaceHolderNeuron(\"library\", neuron)\n",
    "\n",
    "\t\t\t\tdf=loadBsimRun(0.0,False)\n",
    "\t\t\t\tgs=PatchBsimGlobalStats(gs, df)\n",
    "\t\telse:\n",
    "\t\t\tif debug:\n",
    "\t\t\t\tprint(f\"{CYAN}Skipping neuron {neuron} for Simbatch tests{STANDARD}\")\n",
    "\n",
    "\t\t\t# BMsim tests\n",
    "\n",
    "\t\t# BMsim tests\n",
    "\t\tif runBmsimTests and not(any(gs.index.str.startswith(neuron)) and gs.loc[gs.index.str.startswith(neuron), 'bmoccurrences'].max() > 0):\n",
    "\t\t\tseq=getNeuronSeq(\"library\", neuron)\n",
    "\t\t\tif seq!=\"0\":\n",
    "\t\t\t\tfor i in range(0, int(seq)):\n",
    "\t\t\t\t\tif generateNeuron(\"library\", neuron, str(i), benchcore):\n",
    "\t\t\t\t\t\trunBMsim()\n",
    "\t\t\t\t\t\terrors,mse,latency=analyzeBMsim()\n",
    "\t\t\t\t\t\tdf=loadBMsimRun(mse,latency)\n",
    "\t\t\t\t\t\tgs=PatchBMsimGlobalStats(gs, df)\n",
    "\t\t\t\t\telse:\n",
    "\t\t\t\t\t\tprint(f\"{RED}Error generating neuron {neuron} with sequence {seq}{STANDARD}\")\n",
    "\t\t\telse:\n",
    "\t\t\t\tplaceHolderNeuron(\"library\", neuron)\n",
    "\n",
    "\t\t\t\tdf=loadBMsimRun(0.0,False)\n",
    "\t\t\t\tgs=PatchBMsimGlobalStats(gs, df)\n",
    "\t\telse:\n",
    "\t\t\tif debug:\n",
    "\t\t\t\tprint(f\"{CYAN}Skipping neuron {neuron} for BMsim tests{STANDARD}\")\n",
    "\n",
    "\tgs.style.format('{:.10f}', subset=['bsimerror'])\n",
    "\tgs.style.format('{:.10f}', subset=['bmerror'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.style.apply(lambda x: x.map(highlightDone), axis=None, subset=['bsimoccurrences', 'bmoccurrences']) if fullRun else None"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "temp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
